{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\">This document only computes the latency for the retrieval stage</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Before running</h3>\n",
    "Make sure you are running this notebook using the \"sprint_env\" conda environment to ensure a smooth operation.\n",
    "\n",
    "The cell below checks that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.check_output(\"conda info | grep 'active environment'\", shell=True)\n",
    "result_str = result.decode('utf-8').strip().split(\" : \")[1]\n",
    "\n",
    "expected_value = \"sprint_env\"\n",
    "assert result_str == expected_value, f\"Expected value: {expected_value}; Actual value: {result_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Set-up and the required functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cciacu/miniconda3/envs/sprint_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List\n",
    "\n",
    "from pyserini.analysis import JDefaultEnglishAnalyzer, JWhiteSpaceAnalyzer\n",
    "from pyserini.output_writer import OutputFormat, get_output_writer\n",
    "from pyserini.pyclass import autoclass\n",
    "from pyserini.query_iterator import get_query_iterator, TopicsFormat\n",
    "from pyserini.search import JDisjunctionMaxQueryGenerator\n",
    "from pyserini.search.lucene import LuceneImpactSearcher, LuceneSearcher\n",
    "from pyserini.search.lucene.reranker import (\n",
    "    ClassifierType,\n",
    "    PseudoRelevanceClassifierReranker,\n",
    ")\n",
    "from sprint_toolkit.inference import encoder_builders\n",
    "from pathlib import Path\n",
    "\n",
    "import io\n",
    "from contextlib import redirect_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_iterator, topics, args, tokenizer, searcher, fields, query_generator):\n",
    "    batch_topics = list()\n",
    "    batch_topic_ids = list()\n",
    "    for index, (topic_id, text) in enumerate(\n",
    "        tqdm(query_iterator, total=len(topics.keys()))\n",
    "    ):\n",
    "        if args.tokenizer != None:\n",
    "            toks = tokenizer.tokenize(text)\n",
    "            text = \" \"\n",
    "            text = text.join(toks)\n",
    "        if args.batch_size <= 1 and args.threads <= 1:\n",
    "            if args.impact:\n",
    "                hits = searcher.search(text, args.hits, fields=fields)\n",
    "            else:\n",
    "                hits = searcher.search(\n",
    "                    text, args.hits, query_generator=query_generator, fields=fields\n",
    "                )\n",
    "            results = [(topic_id, hits)]\n",
    "        else:\n",
    "            batch_topic_ids.append(str(topic_id))\n",
    "            batch_topics.append(text)\n",
    "            if (index + 1) % args.batch_size == 0 or index == len(topics.keys()) - 1:\n",
    "                if args.impact:\n",
    "                    results = searcher.batch_search(\n",
    "                        batch_topics,\n",
    "                        batch_topic_ids,\n",
    "                        args.hits,\n",
    "                        args.threads,\n",
    "                        fields=fields,\n",
    "                    )\n",
    "                else:\n",
    "                    results = searcher.batch_search(\n",
    "                        batch_topics,\n",
    "                        batch_topic_ids,\n",
    "                        args.hits,\n",
    "                        args.threads,\n",
    "                        query_generator=query_generator,\n",
    "                        fields=fields,\n",
    "                    )\n",
    "                results = [(id_, results[id_]) for id_ in batch_topic_ids]\n",
    "                batch_topic_ids.clear()\n",
    "                batch_topics.clear()\n",
    "            else:\n",
    "                continue\n",
    "        results.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packaging pyserini.search into both callable and entry point\n",
    "# With reference to https://github.com/castorini/pyserini/blob/master/pyserini/search/__main__.py\n",
    "#\n",
    "# Pyserini: Reproducible IR research with sparse and dense representations\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "def set_bm25_parameters(searcher, index, k1=None, b=None):\n",
    "    if k1 is not None or b is not None:\n",
    "        if k1 is None or b is None:\n",
    "            print(\"Must set *both* k1 and b for BM25!\")\n",
    "            exit()\n",
    "        print(f\"Setting BM25 parameters: k1={k1}, b={b}\")\n",
    "        searcher.set_bm25(k1, b)\n",
    "    else:\n",
    "        # Automatically set bm25 parameters based on known index:\n",
    "        if index == \"msmarco-passage\" or index == \"msmarco-passage-slim\":\n",
    "            print(\"MS MARCO passage: setting k1=0.82, b=0.68\")\n",
    "            searcher.set_bm25(0.82, 0.68)\n",
    "        elif index == \"msmarco-passage-expanded\":\n",
    "            print(\"MS MARCO passage w/ doc2query-T5 expansion: setting k1=2.18, b=0.86\")\n",
    "            searcher.set_bm25(2.18, 0.86)\n",
    "        elif index == \"msmarco-doc\" or index == \"msmarco-doc-slim\":\n",
    "            print(\"MS MARCO doc: setting k1=4.46, b=0.82\")\n",
    "            searcher.set_bm25(4.46, 0.82)\n",
    "        elif (\n",
    "            index == \"msmarco-doc-per-passage\"\n",
    "            or index == \"msmarco-doc-per-passage-slim\"\n",
    "        ):\n",
    "            print(\"MS MARCO doc, per passage: setting k1=2.16, b=0.61\")\n",
    "            searcher.set_bm25(2.16, 0.61)\n",
    "        elif index == \"msmarco-doc-expanded-per-doc\":\n",
    "            print(\n",
    "                \"MS MARCO doc w/ doc2query-T5 (per doc) expansion: setting k1=4.68, b=0.87\"\n",
    "            )\n",
    "            searcher.set_bm25(4.68, 0.87)\n",
    "        elif index == \"msmarco-doc-expanded-per-passage\":\n",
    "            print(\n",
    "                \"MS MARCO doc w/ doc2query-T5 (per passage) expansion: setting k1=2.56, b=0.59\"\n",
    "            )\n",
    "            searcher.set_bm25(2.56, 0.59)\n",
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def run(\n",
    "    topics: str,\n",
    "    index: str,\n",
    "    output: str,\n",
    "    topics_format: str = TopicsFormat.DEFAULT.value,\n",
    "    output_format: str = OutputFormat.TREC.value,\n",
    "    max_passage: bool = False,\n",
    "    max_passage_hits: int = 100,\n",
    "    max_passage_delimiter: str = \"#\",\n",
    "    batch_size: int = 1,\n",
    "    threads: int = 1,\n",
    "    remove_duplicates: bool = False,\n",
    "    hits: int = 1000,\n",
    "    impact: bool = False,\n",
    "    encoder_name: str = None,\n",
    "    ckpt_name: str = None,\n",
    "    tokenizer: str = None,\n",
    "    min_idf: int = -1,\n",
    "    bm25: bool = False,\n",
    "    rm3: bool = False,\n",
    "    qld: bool = False,\n",
    "    language: str = \"en\",\n",
    "    prcl: List[ClassifierType] = [],\n",
    "    k1: float = None,\n",
    "    b: float = None,\n",
    "    vectorizer: str = None,\n",
    "    fields=None,\n",
    "    stopwords: str = None,\n",
    "    r: int = 10,\n",
    "    n: int = 100,\n",
    "    alpha: float = 0.5,\n",
    "    dismax: bool = False,\n",
    "    tiebreaker: float = 0.0,\n",
    "    model: str = None,\n",
    "    dataset: str = None\n",
    "):\n",
    "    frame = inspect.currentframe()\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    args = AttrDict(dict(zip(args, map(lambda arg: values[arg], args))))\n",
    "\n",
    "    query_iterator = get_query_iterator(args.topics, TopicsFormat(args.topics_format))\n",
    "    prev_topics = topics\n",
    "    topics = query_iterator.topics\n",
    "\n",
    "    if not args.impact:\n",
    "        if os.path.exists(args.index):\n",
    "            # create searcher from index directory\n",
    "            searcher = LuceneSearcher(args.index)\n",
    "        else:\n",
    "            # create searcher from prebuilt index name\n",
    "            searcher = LuceneSearcher.from_prebuilt_index(args.index)\n",
    "    elif args.impact:\n",
    "        ######## build query encoder by encoder name and checkpoint name ##########\n",
    "        encoder_builder = encoder_builders.get_builder(encoder_name, ckpt_name, \"query\")\n",
    "        args.encoder = encoder_builder()  # By default this will use CPU\n",
    "        ###########################################################################\n",
    "        if os.path.exists(args.index):\n",
    "            searcher = LuceneImpactSearcher(args.index, args.encoder, args.min_idf)\n",
    "        else:\n",
    "            searcher = LuceneImpactSearcher.from_prebuilt_index(\n",
    "                args.index, args.encoder, args.min_idf\n",
    "            )\n",
    "\n",
    "    if args.language != \"en\":\n",
    "        searcher.set_language(args.language)\n",
    "\n",
    "    if not searcher:\n",
    "        exit()\n",
    "\n",
    "    search_rankers = []\n",
    "\n",
    "    if args.qld:\n",
    "        search_rankers.append(\"qld\")\n",
    "        searcher.set_qld()\n",
    "    elif args.bm25:\n",
    "        search_rankers.append(\"bm25\")\n",
    "        set_bm25_parameters(searcher, args.index, args.k1, args.b)\n",
    "\n",
    "    if args.rm3:\n",
    "        search_rankers.append(\"rm3\")\n",
    "        searcher.set_rm3()\n",
    "\n",
    "    fields = dict()\n",
    "    if args.fields:\n",
    "        fields = dict([pair.split(\"=\") for pair in args.fields])\n",
    "        print(f\"Searching over fields: {fields}\")\n",
    "\n",
    "    query_generator = None\n",
    "    if args.dismax:\n",
    "        query_generator = JDisjunctionMaxQueryGenerator(args.tiebreaker)\n",
    "        print(f\"Using dismax query generator with tiebreaker={args.tiebreaker}\")\n",
    "\n",
    "    if args.tokenizer != None:\n",
    "        analyzer = JWhiteSpaceAnalyzer()\n",
    "        searcher.set_analyzer(analyzer)\n",
    "        print(f\"Using whitespace analyzer because of pretokenized topics\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.tokenizer)\n",
    "        print(f\"Using {args.tokenizer} to preprocess topics\")\n",
    "\n",
    "    if args.stopwords:\n",
    "        analyzer = JDefaultEnglishAnalyzer.fromArguments(\n",
    "            \"porter\", False, args.stopwords\n",
    "        )\n",
    "        searcher.set_analyzer(analyzer)\n",
    "        print(f\"Using custom stopwords={args.stopwords}\")\n",
    "\n",
    "    # get re-ranker\n",
    "    use_prcl = args.prcl and len(args.prcl) > 0 and args.alpha > 0\n",
    "    if use_prcl is True:\n",
    "        ranker = PseudoRelevanceClassifierReranker(\n",
    "            searcher.index_dir,\n",
    "            args.vectorizer,\n",
    "            args.prcl,\n",
    "            r=args.r,\n",
    "            n=args.n,\n",
    "            alpha=args.alpha,\n",
    "        )\n",
    "\n",
    "    # build output path\n",
    "    \n",
    "    #### \n",
    "    # This branch is not visited\n",
    "    ####\n",
    "    output_path = args.output\n",
    "    if output_path is None:\n",
    "        if use_prcl is True:\n",
    "            clf_rankers = []\n",
    "            for t in args.prcl:\n",
    "                if t == ClassifierType.LR:\n",
    "                    clf_rankers.append(\"lr\")\n",
    "                elif t == ClassifierType.SVM:\n",
    "                    clf_rankers.append(\"svm\")\n",
    "\n",
    "            r_str = f\"prcl.r_{args.r}\"\n",
    "            n_str = f\"prcl.n_{args.n}\"\n",
    "            a_str = f\"prcl.alpha_{args.alpha}\"\n",
    "            clf_str = \"prcl_\" + \"+\".join(clf_rankers)\n",
    "            tokens1 = [\"run\", args.topics, \"+\".join(search_rankers)]\n",
    "            tokens2 = [args.vectorizer, clf_str, r_str, n_str, a_str]\n",
    "            output_path = \".\".join(tokens1) + \"-\" + \"-\".join(tokens2) + \".txt\"\n",
    "        else:\n",
    "            tokens = [\"run\", args.topics, \"+\".join(search_rankers), \"txt\"]\n",
    "            output_path = \".\".join(tokens)\n",
    "\n",
    "    print(f\"Running {args.topics} topics, saving to {output_path}...\")\n",
    "\n",
    "    ####\n",
    "    # Timing the search\n",
    "    ####\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        %timeit -n 1 -r 5 search(query_iterator, topics, args, tokenizer, searcher, fields, query_generator)\n",
    "\n",
    "    timeit_result = f.getvalue()\n",
    "    number_of_queries = None\n",
    "\n",
    "    try:\n",
    "        elapsed_time = float(timeit_result.split(\" s +- \")[0]) * 1000\n",
    "\n",
    "        with open(prev_topics, \"r\") as file:\n",
    "            number_of_queries = len([line for line in file])\n",
    "\n",
    "        with open(Path(f\"latency/{model}/{dataset}.txt\").resolve().as_posix(), \"a\") as file:\n",
    "            file.write('Latency for retrieval:\\n')\n",
    "            file.write(f\"Timeit result: {timeit_result}\")\n",
    "            file.write(f\"There are {number_of_queries} queries in the dataset.\\n\")\n",
    "            file.write(f\"This comes to {round(float(elapsed_time / number_of_queries), 2)} ms/query\\n\\n\")\n",
    "    except:\n",
    "        elapsed_time = float(timeit_result.split(\" ms +- \")[0])\n",
    "\n",
    "        with open(prev_topics, \"r\") as file:\n",
    "            number_of_queries = len([line for line in file])\n",
    "\n",
    "        with open(Path(f\"latency/{model}/{dataset}.txt\").resolve().as_posix(), \"a\") as file:\n",
    "            file.write('Latency for retrieval:\\n')\n",
    "            file.write(f\"Timeit result: {timeit_result}\")\n",
    "            file.write(f\"There are {number_of_queries} queries in the dataset.\\n\")\n",
    "            file.write(f\"This comes to {round(float(elapsed_time / number_of_queries), 2)} ms/query\\n\\n\")\n",
    "    \n",
    "    print(f\"{__name__}: Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_split = \"test\"\n",
    "###\n",
    "dataset = \"nfcorpus\"\n",
    "###\n",
    "model='unicoil'\n",
    "# model='deepimpact'\n",
    "ckpt_name='castorini/unicoil-noexp-msmarco-passage' \n",
    "# ckpt_name='/Users/cciacu/Desktop/school/rp/experiments/deepimpact-bert-base' \n",
    "###\n",
    "\n",
    "topics=Path(f\"queries/queries_{model}_{dataset}_{topic_split}.tsv\").resolve().as_posix()\n",
    "index=Path(f\"sparse_indexes/sparse_index_{dataset}_{model}\").resolve().as_posix()\n",
    "output=Path(f\"sprint_searches/search-{dataset}-{model}-{topic_split}.tsv\").resolve().as_posix()\n",
    "\n",
    "encoder_name=model\n",
    "impact=True\n",
    "hits=1000 + 1\n",
    "batch_size=128\n",
    "threads=12\n",
    "output_format='trec'\n",
    "min_idf=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /Users/cciacu/Desktop/school/rp/experiments/queries/queries_unicoil_nfcorpus_test.tsv topics, saving to /Users/cciacu/Desktop/school/rp/experiments/sprint_searches/search-nfcorpus-unicoil-test.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:13<00:00, 23.25it/s]\n",
      "100%|██████████| 323/323 [00:14<00:00, 23.07it/s]\n",
      "100%|██████████| 323/323 [00:13<00:00, 23.91it/s]\n",
      "100%|██████████| 323/323 [00:12<00:00, 24.87it/s]\n",
      "100%|██████████| 323/323 [00:14<00:00, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__: Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(topics=topics, encoder_name=encoder_name, ckpt_name=ckpt_name, index=index,\n",
    "    output=output, impact=impact, hits=hits, batch_size=batch_size, threads=threads,\n",
    "    output_format=output_format, min_idf=min_idf, model=model, dataset=dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
