{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "Create a new conda environment from this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Retrieving notices: ...working... ^C\n"
     ]
    }
   ],
   "source": [
    "!conda env create -f rp-splade.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creation, search for **'splade_final'** in your IDEs available interpreters and **select** it for this notebook.\n",
    "\n",
    "If you successfully selected it, then the next cell should pass the assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.check_output(\"conda info | grep 'active environment'\", shell=True)\n",
    "result_str = result.decode('utf-8').strip().split(\" : \")[1]\n",
    "\n",
    "expected_value = \"rp-splade\"\n",
    "assert result_str == expected_value, f\"Expected value: {expected_value}; Actual value: {result_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "from pyterrier.measures import RR, nDCG, MAP, R, MRR\n",
    "from fast_forward.encoder import TCTColBERTQueryEncoder, TCTColBERTDocumentEncoder, TransformerEncoder\n",
    "from fast_forward import OnDiskIndex, Mode, Indexer\n",
    "from fast_forward.util.pyterrier import FFScore, FFInterpolate\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set-up\n",
    "### 2.1. Encoder settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at castorini/tct_colbert-msmarco were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at castorini/tct_colbert-msmarco were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Transformer name\n",
    "transformer_name = 'castorini/tct_colbert-msmarco'\n",
    "\n",
    "# Dual-encoder architecture\n",
    "q_encoder = TCTColBERTQueryEncoder(transformer_name)\n",
    "d_encoder = TCTColBERTDocumentEncoder(\n",
    "    transformer_name, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Initialize Pyterrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset names (human readable format)\n",
    "dataset_names = ['fiqa', 'nfcorpus', 'scifact', 'quora', 'hotpotqa', 'dbpedia', 'fever']\n",
    "\n",
    "testset_names = ['irds:beir/fiqa/test', 'irds:beir/nfcorpus/test', 'irds:beir/scifact/test',\n",
    "                 'irds:beir/quora/test', 'irds:beir/hotpotqa/test', 'irds:beir/dbpedia-entity/test',\n",
    "                 'irds:beir/fever/test']\n",
    "\n",
    "# List of sparse indexes (relative paths from the current directory) that are going to be used in the evaluations\n",
    "sparse_indexes = ['sparse_indexes/sparse_index_fiqa', 'sparse_indexes/sparse_index_nfcorpus', \n",
    "                  'sparse_indexes/sparse_index_scifact', 'sparse_indexes/sparse_index_quora',\n",
    "                  'sparse_indexes/sparse_index_hotpotqa',\n",
    "                  'sparse_indexes/sparse_index_dbpedia-entity_with_encoding',\n",
    "                  'sparse_indexes/sparse_index_fever_with_encoding']\n",
    "\n",
    "dense_indexes = ['dense_indexes/ffindex_fiqa_tct.h5', 'dense_indexes/ffindex_nfcorpus_tct.h5',\n",
    "                 'dense_indexes/ffindex_scifact_tct.h5', 'dense_indexes/ffindex_quora_tct.h5',\n",
    "                 'dense_indexes/ffindex_hotpotqa_tct.h5', 'dense_indexes/ffindex_dbpedia-entity_tct.h5',\n",
    "                 'dense_indexes/ffindex_fever_tct.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwapQueries(pt.Transformer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if 'query_0' in df:\n",
    "            df_new = df.copy()\n",
    "            df_new[\"query_copy\"] = df_new[\"query\"]\n",
    "            df_new[\"query\"] = df_new[\"query_0\"]\n",
    "            df_new[\"query_0\"] = df_new[\"query_copy\"]\n",
    "            df_new = df_new.drop(columns=[\"query_copy\"])\n",
    "            return df_new\n",
    "        return df\n",
    "\n",
    "def read_alpha_from_file(retrieval_model_name: str, dataset_name: str) -> float:\n",
    "    with open(f\"alpha_tuning/{retrieval_model_name}/{dataset_name}.txt\", \"r\") as file:\n",
    "        lines = [line for line in file]\n",
    "        return float(lines[-2].split(\": \")[1])\n",
    "\n",
    "def ff_with_swap(input, ff_score: FFScore, alpha: float) -> pd.DataFrame:\n",
    "    return (SwapQueries() >> ff_score >> FFInterpolate(alpha))(input)\n",
    "\n",
    "def ff(input, ff_score: FFScore, alpha: float) -> pd.DataFrame:\n",
    "    return (ff_score >> FFInterpolate(alpha))(input)\n",
    "\n",
    "def retrieve(topics, model) -> pd.DataFrame:\n",
    "    return model(topics)\n",
    "\n",
    "def measure_retrieval(test_set, curr_index, model, model_name: str) -> pd.DataFrame:\n",
    "    topics = test_set.get_topics()\n",
    "    \n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        %timeit retrieve(topics, model)\n",
    "\n",
    "    # Extract the output from the StringIO object\n",
    "    timeit_result = f.getvalue()\n",
    "    elapsed_time = float(timeit_result.split(\" s +- \")[0]) * 1000 # convert miliseconds to seconds\n",
    "    number_of_queries = len(test_set.get_topics())\n",
    "\n",
    "    with open(f\"latency/{model_name}/{dataset_names[curr_index]}.txt\", \"a\") as file1:\n",
    "        file1.write('Latency for retrieval:\\n')\n",
    "        file1.write(f\"Timeit result: {timeit_result}\")\n",
    "        file1.write(f\"There are {number_of_queries} queries in the dataset.\\n\")\n",
    "        file1.write(f\"This comes to {round(float(elapsed_time / number_of_queries), 2)} ms/query \\n\\n\")\n",
    "\n",
    "    return retrieve(topics, model)\n",
    "\n",
    "def measure_reranking(input_df: pd.DataFrame, test_set, curr_index, model_name: str, ff_score=None, alpha=None):\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        if model_name.lower() in ['deepct', 'splade']:\n",
    "            %timeit ff_with_swap(input_df, ff_score, alpha)\n",
    "        else:\n",
    "            %timeit ff(input_df, ff_score, alpha)\n",
    "\n",
    "    # Extract the output from the StringIO object\n",
    "    timeit_result = f.getvalue()\n",
    "    elapsed_time = float(timeit_result.split(\" s +- \")[0]) * 1000 # convert miliseconds to seconds\n",
    "    number_of_queries = len(test_set.get_topics())\n",
    "\n",
    "    with open(f\"latency/{model_name}/{dataset_names[curr_index]}.txt\", \"a\") as file1:\n",
    "        file1.write('Latency for re-ranking:\\n')\n",
    "        file1.write(f\"Timeit result: {timeit_result}\")\n",
    "        file1.write(f\"There are {number_of_queries} queries in the dataset.\\n\")\n",
    "        file1.write(f\"This comes to {round(float(elapsed_time / number_of_queries), 2)} ms/query \\n\\n\\n\")\n",
    "\n",
    "def measure_latency(test_set, curr_index, model, model_name: str, ff_score=None, alpha=None):\n",
    "    retrieval = measure_retrieval(test_set, curr_index, model, model_name)\n",
    "    measure_reranking(retrieval, test_set, curr_index, model_name, ff_score, alpha)\n",
    "\n",
    "def measure_reranking_sprint(file_path, test_set, curr_index, model_name, ff_score, alpha):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Read the TSV file into a DataFrame without header\n",
    "    df = pd.read_csv(file_path, sep=' ', header=None)\n",
    "\n",
    "    # Assign column names\n",
    "    df.columns = ['qid', 'ignore_1', 'docno', 'rank', 'score', 'ignore_2']\n",
    "\n",
    "    # Optionally, drop the columns that you don't need\n",
    "    df = df[['qid', 'docno', 'rank', 'score']]\n",
    "\n",
    "    topics = test_set.get_topics()\n",
    "    topics['qid'] = topics['qid'].astype('str')\n",
    "    df['qid'] = df['qid'].astype('str')\n",
    "\n",
    "    df_merged = pd.merge(df, topics, on='qid')\n",
    "    df_merged['docno'] = df_merged['docno'].astype('str')\n",
    "\n",
    "    measure_reranking(df_merged, test_set, curr_index, model_name, ff_score, alpha)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic(curr_index):\n",
    "    # Load ffindex for the current dataset\n",
    "    ff_index = OnDiskIndex.load(\n",
    "        Path(dense_indexes[curr_index]).resolve(), query_encoder=q_encoder, mode=Mode.MAXP\n",
    "    )\n",
    "\n",
    "    # Load it into the main memory\n",
    "    ff_index = ff_index.to_memory()\n",
    "\n",
    "    # Initialize Fast-Forward Indexes\n",
    "    ff_score = FFScore(ff_index)\n",
    "\n",
    "    # Load sparse indexes\n",
    "    index_ref = pt.IndexFactory.of(Path(sparse_indexes[curr_index]).resolve().as_posix(), memory=True)\n",
    "    deepct_index_ref = pt.IndexFactory.of(Path(sparse_indexes[curr_index] + \"_deepct\").resolve().as_posix(), memory=True)\n",
    "    splade_index_ref = pt.IndexFactory.of(Path(sparse_indexes[curr_index] + \"_splade\").resolve().as_posix(), memory=True)\n",
    "\n",
    "    # Retrieval models\n",
    "    bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "    alpha_bm25 = read_alpha_from_file('bm25', dataset_names[curr_index])\n",
    "\n",
    "    tf_idf = pt.BatchRetrieve(index_ref, wmodel=\"TF_IDF\")\n",
    "    alpha_tfidf = read_alpha_from_file('tf_idf', dataset_names[curr_index])\n",
    "\n",
    "    deep_ct = pt.BatchRetrieve(deepct_index_ref, wmodel=\"BM25\")\n",
    "    alpha_deepct = read_alpha_from_file('deepct', dataset_names[curr_index])\n",
    "\n",
    "    # Splade\n",
    "    import pyt_splade\n",
    "    factory = pyt_splade.SpladeFactory()\n",
    "    splade = factory.query() >> pt.BatchRetrieve(splade_index_ref, wmodel=\"Tf\")\n",
    "    alpha_splade = read_alpha_from_file('splade', dataset_names[curr_index])\n",
    "\n",
    "    test_set = pt.get_dataset(testset_names[curr_index])\n",
    "\n",
    "    # Measure latency: BM25 + FF\n",
    "    measure_latency(model=bm25, alpha=alpha_bm25, model_name=\"bm25\", test_set=test_set, curr_index=curr_index, ff_score=ff_score)\n",
    "    print('Finished for BM25')\n",
    "\n",
    "    # Measure latency: TF-IDF + FF\n",
    "    measure_latency(model=tf_idf, alpha=alpha_tfidf, model_name=\"tfidf\", test_set=test_set, curr_index=curr_index, ff_score=ff_score)\n",
    "    print('Finished for TF-IDF')\n",
    "\n",
    "    # Measure latency: DeepCT + FF\n",
    "    measure_latency(model=deep_ct, alpha=alpha_deepct, model_name=\"deepct\", test_set=test_set, curr_index=curr_index, ff_score=ff_score)\n",
    "    print('Finished for DeepCT')\n",
    "\n",
    "    # Measure latency: SPLADE + FF\n",
    "    measure_latency(model=splade, alpha=alpha_splade, model_name=\"splade\", test_set=test_set, curr_index=curr_index, ff_score=ff_score)\n",
    "    print('Finished for SPLADE')\n",
    "\n",
    "    # Measure latency: uniCOIL + FF\n",
    "    alpha_unicoil = read_alpha_from_file('unicoil', dataset_names[curr_index])\n",
    "    measure_reranking_sprint(file_path=f'runs/unicoil_{dataset_names[curr_index]}_test_run.tsv',\n",
    "                            test_set=test_set, curr_index=curr_index, model_name=\"unicoil\",\n",
    "                            ff_score=ff_score, alpha=alpha_unicoil)\n",
    "\n",
    "    # Measure latency: DeepImpact + FF\n",
    "    alpha_deepimpact = read_alpha_from_file('deepimpact', dataset_names[curr_index])\n",
    "    measure_reranking_sprint(file_path=f'runs/deepimpact_{dataset_names[curr_index]}_test_run.tsv',\n",
    "                            test_set=test_set, curr_index=curr_index, model_name=\"deepimpact\",\n",
    "                            ff_score=ff_score, alpha=alpha_deepimpact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3633/3633 [00:00<00:00, 1690658.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for BM25\n",
      "Finished for TF-IDF\n",
      "Finished for DeepCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for SPLADE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 2318834.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for BM25\n",
      "Finished for TF-IDF\n",
      "Finished for DeepCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/cciacu/miniconda3/envs/splade_final/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for SPLADE\n"
     ]
    }
   ],
   "source": [
    "for curr_index in range(1, 3):\n",
    "    logic(curr_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splade_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
